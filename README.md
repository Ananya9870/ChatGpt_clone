ğŸ’» Chatgpt: AI Chatbot for Coders with OCR

Chatgpt is an interactive Streamlit-based AI assistant built for developers and learners.
It integrates with Ollamaâ€™s local LLM API (such as llama2:latest) to provide real-time coding help, debugging assistance, and general Q&A â€” right from your desktop.

It also includes a built-in OCR (Optical Character Recognition) module that allows users to extract text from images (e.g., code snippets, screenshots, or notes) and send it directly to the chatbot for further discussion.

ğŸ§  Key Features
ğŸ¤– AI Chat Assistant

Powered by Ollamaâ€™s local model (llama2:latest)

Provides context-aware responses

Maintains conversation history across sessions

Chat interface styled like ChatGPT

ğŸ“¸ OCR Integration

Upload images (.jpg, .jpeg, .png)

Extract text instantly using Tesseract OCR

Send extracted text directly to the chat interface

ğŸ§¾ Persistent Chat History

Saves conversations locally as chat_history.json

Reloads previous sessions automatically

Allows clearing current chat or entire history easily

ğŸ’¬ Modern UI

Built with Streamlit

Clean, ChatGPT-like dark interface

Interactive sidebar with expandable past conversations

âš™ï¸ Tech Stack
Component	Technology
Frontend/UI	Streamlit
Backend AI	Ollama (Local LLM - e.g., Llama 2)
OCR Engine	Tesseract OCR
Language	Python
Persistence	Local JSON file (chat_history.json)
ğŸ› ï¸ Installation & Setup
1. Clone the Repository
git clone https://github.com/your-username/bytebuddy-ai.git
cd bytebuddy-ai

2. Install Dependencies

Make sure you have Python 3.8+ installed.
Then install the required libraries:

pip install streamlit streamlit-chat requests pillow pytesseract

3. Install & Configure Tesseract OCR

Windows:
Download from Tesseract at UB Mannheim

Then set the executable path in the code:

pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"


macOS (Homebrew):

brew install tesseract


Linux (Ubuntu):

sudo apt install tesseract-ocr

4. Install and Run Ollama

Download and install Ollama (for local LLM models):
ğŸ”— https://ollama.ai/download

Then pull a model like Llama 2:

ollama pull llama2


Start the Ollama server locally:

ollama serve

ğŸš€ Run the Application

Once everything is set up, start the Streamlit app:

streamlit run app.py


ğŸ’¡ The app will automatically open in your default browser at
http://localhost:8501

ğŸ§© File Structure
ğŸ“ bytebuddy-ai/
â”‚
â”œâ”€â”€ app.py                  # Main Streamlit application
â”œâ”€â”€ chat_history.json       # Persistent local chat history
â”œâ”€â”€ requirements.txt        # Python dependencies (optional)
â””â”€â”€ README.md               # Project documentation

ğŸ–¼ï¸ App Walkthrough
ğŸ  Main Interface

A clean dark-themed chat UI

Type messages at the bottom input bar

AI responds with contextual answers

ğŸ“¸ OCR Module

Upload an image â†’ Extract text â†’ Send to chat

Perfect for extracting code or notes

ğŸ—‚ï¸ Sidebar

View and reopen past chats

Buttons to clear chat or full history

ğŸ’¡ Example Use Cases

Ask coding-related questions (Python, Java, C, etc.)

Debug errors by pasting code snippets

Extract text from screenshots (OCR) and analyze it

Discuss algorithms, LeetCode problems, or ML concepts

âš ï¸ Troubleshooting
Issue	Possible Fix
TesseractNotFoundError	Verify installation path in pytesseract.pytesseract.tesseract_cmd
Ollama not responding	Ensure Ollama server is running locally (ollama serve)
Empty responses	Check that the model name (llama2:latest) is available locally
Streamlit not found	Run pip install streamlit again
ğŸ§‘â€ğŸ’» Contributing

Contributions are welcome!
If youâ€™d like to add new features or improve the UI:

Fork the repository

Create a new branch (feature/improve-ui)

Commit changes

Submit a pull request ğŸ‰

ğŸ“œ License

This project is licensed under the MIT License â€” feel free to use, modify, and distribute with attribution.
